{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0           0      3            0                   0        3      2   \n",
      "1           1      3            0                   3        0      1   \n",
      "2           2      3            0                   3        0      1   \n",
      "3           3      3            0                   2        1      1   \n",
      "4           4      6            0                   6        0      1   \n",
      "\n",
      "                                               tweet  \n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
      "                                               tweet  \\\n",
      "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "\n",
      "                         labels  \n",
      "0  No Hate and Offensive Speech  \n",
      "1              Offensive Speech  \n",
      "2              Offensive Speech  \n",
      "3              Offensive Speech  \n",
      "4              Offensive Speech  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mastk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mastk\\OneDrive\\Documents\\Desktop\\ML & AI\\Hate_speech_detection\\Hate_detection.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=29'>30</a>\u001b[0m     text\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m join(text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=31'>32</a>\u001b[0m data[\u001b[39m\"\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39;49m\u001b[39mtweet\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49m apply(clean)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=32'>33</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39m array(data[\u001b[39m\"\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=33'>34</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39m array(data[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\mastk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\mastk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1085\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\mastk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1137\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1138\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1144\u001b[0m             values,\n\u001b[0;32m   1145\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1146\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1147\u001b[0m         )\n\u001b[0;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1150\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\mastk\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\mastk\\OneDrive\\Documents\\Desktop\\ML & AI\\Hate_speech_detection\\Hate_detection.ipynb Cell 1'\u001b[0m in \u001b[0;36mclean\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=21'>22</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39m sub(\u001b[39m'\u001b[39m\u001b[39mhttps?://\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS+|www.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mS+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=22'>23</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39m sub(\u001b[39m'\u001b[39m\u001b[39m<.?>+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=23'>24</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m re\u001b[39m.\u001b[39mescape(string\u001b[39m.\u001b[39mpunctuation), \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=24'>25</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39m sub(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mastk/OneDrive/Documents/Desktop/ML%20%26%20AI/Hate_speech_detection/Hate_detection.ipynb#ch0000000?line=25'>26</a>\u001b[0m text \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39m sub(\u001b[39m'\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string' is not defined"
     ]
    }
   ],
   "source": [
    "#Importing the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword=set(stopwords.words('english'))\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "data = pd.read_csv(r\"C:\\Users\\mastk\\OneDrive\\Documents\\Desktop\\ML & AI\\Hate_speech_detection\\labeled_data.csv\")\n",
    "#To preview the data\n",
    "print(data.head())\n",
    "data[\"labels\"] = data[\"class\"]. map({0: \"Hate Speech\", 1: \"Offensive Speech\", 2: \"No Hate and Offensive Speech\"})\n",
    "data = data[[\"tweet\", \"labels\"]]\n",
    "print(data. head())\n",
    "def clean (text):\n",
    "    text = str(text).lower()\n",
    "    text = re. sub('[.?]', '', text)\n",
    "    text = re. sub('https?://\\S+|www.\\S+', '', text)\n",
    "    text = re. sub('<.?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re. sub('\\n', '', text)\n",
    "    text = re. sub('\\w\\d\\w', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \". join(text)\n",
    "    text = [stemmer. stem(word) for word in text. split(' ')]\n",
    "    text=\" \". join(text)\n",
    "    return text\n",
    "data[\"tweet\"] = data[\"tweet\"]. apply(clean)\n",
    "x = np. array(data[\"tweet\"])\n",
    "y = np. array(data[\"labels\"])\n",
    "cv = CountVectorizer()\n",
    "X = cv. fit_transform(x)\n",
    "#Splitting the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#Model building\n",
    "model = DecisionTreeClassifier()\n",
    "#Training the model\n",
    "model. fit(X_train,y_train)\n",
    "#Testing the model\n",
    "y_pred = model. predict (X_test)\n",
    "y_pred#Accuracy Score of our model\n",
    "from sklearn. metrics import accuracy_score\n",
    "print (accuracy_score (y_test,y_pred))\n",
    "#Predicting the outcome\n",
    "inp = \"You are too bad and I dont like your attitude\"\n",
    "inp = cv.transform([inp]).toarray()\n",
    "print(model.predict(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>No Hate and Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "      <td>No Hate and Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>Offensive Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "      <td>No Hate and Offensive Speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  \\\n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "...                                                  ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
       "24779  you've gone and broke the wrong heart baby, an...   \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
       "24781              youu got wild bitches tellin you lies   \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
       "\n",
       "                             labels  \n",
       "0      No Hate and Offensive Speech  \n",
       "1                  Offensive Speech  \n",
       "2                  Offensive Speech  \n",
       "3                  Offensive Speech  \n",
       "4                  Offensive Speech  \n",
       "...                             ...  \n",
       "24778              Offensive Speech  \n",
       "24779  No Hate and Offensive Speech  \n",
       "24780              Offensive Speech  \n",
       "24781              Offensive Speech  \n",
       "24782  No Hate and Offensive Speech  \n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "583730cd0bdb9df2d5707731e21524ebc1874ac3158e54b6663f41b950929600"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
